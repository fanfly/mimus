#!/usr/bin/env python3
import argparse
import sys

def parse_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser(prog='tokenize')
    parser.add_argument(
        '-m',
        '--model-path',
        help='path to the model file',
        required=True,
    )
    return parser.parse_args()

def tokenize(text: str, model_path: str) -> list[int]:
    import transformers

    def get_tokenizer(gguf_path: str) -> transformers.PreTrainedTokenizer:
        return transformers.AutoTokenizer.from_pretrained(
            '.',
            gguf_file=gguf_path,
            legacy=False,
        )

    tokenizer = get_tokenizer(model_path)
    tokens = tokenizer.encode(text)
    return tokens

if __name__ == '__main__':
    args = parse_args()
    prompt = sys.stdin.read()
    tokens = tokenize(prompt, args.model_path)
    print(tokens)
